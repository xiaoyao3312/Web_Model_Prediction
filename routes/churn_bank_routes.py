import os
import sys
import logging
# ä¿®æ­£: æ–°å¢ make_response ç¢ºä¿æ‰¹æ¬¡ä¸‹è¼‰åŠŸèƒ½æ­£å¸¸
from flask import Blueprint, jsonify, request, send_file, make_response
import pandas as pd
import numpy as np
from werkzeug.exceptions import BadRequest
from typing import Any, Dict, List, Tuple, Callable
import matplotlib
# è¨­ç½® Matplotlib ç‚ºéäº’å‹•å¼å¾Œç«¯ï¼Œä»¥ç¢ºä¿åœ¨ä¼ºæœå™¨ç’°å¢ƒä¸­é‹è¡Œ
matplotlib.use('Agg')

import io
import base64

import matplotlib.pyplot as plt
import matplotlib.font_manager as fm # ä¿ç•™ fmï¼Œä½†ä¸å†ç”¨æ–¼å¿«å–æ¸…ç†
import shap

# --- å°å…¥ config.py ä»¥å–å¾—æ¨¡å‹è·¯å¾‘ ---
# è¨­å®šå°ˆæ¡ˆæ ¹è·¯å¾‘ (Web_Model_Prediction)ï¼Œå°å…¥ config.py å’Œ services
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(PROJECT_ROOT)

# å°å…¥ config å’Œ Service
from config import Config
from services.churn_bank_service import ChurnBankService

# -------------------------------------


# --- æ—¥èªŒè¨­å®š (ç§»å‹•åˆ°é ‚éƒ¨) ---
logger = logging.getLogger('ChurnBankRoute')
logger.setLevel(logging.INFO)
# -----------------------------


# =======================================================================
# ğŸ“Œ å·²ç§»é™¤ï¼šå¼·åˆ¶æ¸…é™¤ Matplotlib å­—é«”å¿«å–çš„é‚è¼¯ (é¿å…æœ¬åœ°æˆ–å®¹å™¨ç’°å¢ƒå•é¡Œ)
# =======================================================================
# æ•´å€‹ try...except å€å¡Šå·²ç§»é™¤ï¼Œä»¥é¿å…åœ¨ä¸éœ€è¦ä¸­æ–‡å­—é«”çš„ç’°å¢ƒä¸­å˜—è©¦å¿«å–æ¸…ç†ã€‚
logger.info("Matplotlib font cache cleanup logic has been removed for stability.")

# =======================================================================
# ğŸ“Œ å…¨å±€è¨­å®š Matplotlib (å·²ç§»é™¤ä¸­æ–‡å­—é«”é…ç½®ï¼Œåƒ…ä¿ç•™åŸºç¤è¨­å®š)
# ç¢ºä¿åœ¨ä»»ä½•ç’°å¢ƒä¸‹åœ–è¡¨éƒ½èƒ½ç©©å®šç”Ÿæˆï¼Œä¸ä¾è³´ç‰¹å®šå­—é«”ã€‚
# =======================================================================
# è¨»é‡‹æ‰æˆ–ç§»é™¤æ‰€æœ‰ä¸­æ–‡å­—é«”é…ç½®ï¼Œåƒ…ä¿ç•™åŸºç¤è¨­å®š
# plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'PingFang HK', 'Heiti TC', 'SimHei', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False # ç¢ºä¿è² è™Ÿæ­£å¸¸é¡¯ç¤º
# =======================================================================

# --- æ¨¡å‹èˆ‡è³‡æºè·¯å¾‘å®šç¾© (å¾ Config è®€å–ä¸¦é‡æ–°çµ„è£) ---
# å‡è¨­ MODEL_BANK_PATH æ˜¯ 'data/models/...'ï¼Œå› æ­¤ MODEL_DIR æ‡‰è©²æ˜¯ 'data/models'
# ç‚ºäº†ç©©å®šæ€§ï¼Œæˆ‘å€‘å°‡å…¶é‡æ–°è¨ˆç®—ç‚ºçµ•å°è·¯å¾‘
MODEL_PATH_RELATIVE = Config.MODEL_BANK_PATH
# å‡è¨­æ¨¡å‹æª”æ¡ˆåœ¨ 'data/models' è£¡é¢
MODEL_DIR = os.path.join(PROJECT_ROOT, os.path.dirname(MODEL_PATH_RELATIVE))

# é‡æ–°å®šç¾©å®Œæ•´æ¨¡å‹è·¯å¾‘
MODEL_PATH_FULL = os.path.join(PROJECT_ROOT, MODEL_PATH_RELATIVE)
# å®šç¾©å…¨å±€ SHAP åœ–è¡¨è·¯å¾‘ (å‡å®šèˆ‡æ¨¡å‹æª”æ¡ˆåœ¨åŒä¸€å€‹ç›®éŒ„)
GLOBAL_SHAP_FILE = os.path.join(MODEL_DIR, "shap_summary_plot.png")

# --- ç‰¹å¾µå·¥ç¨‹é¡ (ä¿æŒä¸è®Š) ---
class FeatureEngineerForAPI:
    @staticmethod
    def cast_columns(df: pd.DataFrame, int_cols: Any = None, cat_cols: Any = None) -> pd.DataFrame:
        df_copy = df.copy()
        if int_cols:
            for col in int_cols:
                if col in df_copy.columns:
                    # è™•ç† NaN/Noneï¼Œé˜²æ­¢è½‰æ›å¤±æ•—
                    df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce').fillna(0).astype(int)
        if cat_cols:
            for col in cat_cols:
                if col in df_copy.columns:
                    df_copy[col] = df_copy[col].astype('category')
        return df_copy

    @staticmethod
    def run_v1_preprocessing(df: pd.DataFrame) -> pd.DataFrame:
        df_copy = df.copy()
        
        # è½‰æ›æ•¸å€¼è¼¸å…¥çš„ Geography/Gender ç‚ºé¡åˆ¥åç¨±
        # ç”±æ–¼å‰ç«¯å–®ä¸€é æ¸¬ä½¿ç”¨ 0/1/2ï¼ŒCSV æ‰¹æ¬¡å¯èƒ½ä½¿ç”¨åç¨±ï¼Œé€™è£¡ç¢ºä¿èƒ½è™•ç†æ•¸å€¼
        # è™•ç† 'Gender'ï¼Œå‡è¨­ 'Male'/'Female' æˆ– 0/1
        if df_copy['Gender'].dtype in ['int64', 'float64']:
            df_copy['Gender'] = df_copy['Gender'].replace({0: 'Male', 1: 'Female'})
        df_copy['Gender'] = df_copy['Gender'].astype('category')

        # è™•ç† 'Geography'ï¼Œå‡è¨­ 'France'/'Spain'/'Germany' æˆ– 0/1/2
        geo_map = {0: 'France', 1: 'Spain', 2: 'Germany'}
        if df_copy['Geography'].dtype in ['int64', 'float64']:
            df_copy['Geography'] = df_copy['Geography'].replace(geo_map)
        df_copy['Geography'] = df_copy['Geography'].astype('category')

        # ç‰¹å¾µå·¥ç¨‹ V1
        df_copy['Age_bin'] = pd.cut(df_copy['Age'], bins=[0, 25, 35, 45, 60, np.inf],
                                       labels=['very_young', 'young', 'mid', 'mature', 'senior'],
                                       right=False).astype('category') # ä¿®æ­£ï¼šè¨­ç½® right=False
        df_copy['Is_two_products'] = (df_copy['NumOfProducts'] == 2).astype(int)
        df_copy['Germany_Female'] = ((df_copy['Geography'] == 'Germany') & (df_copy['Gender'] == 'Female')).astype(int)
        df_copy['Germany_Inactive'] = ((df_copy['Geography'] == 'Germany') & (df_copy['IsActiveMember'] == 0)).astype(int)
        df_copy['Has_Zero_Balance'] = (df_copy['Balance'] == 0).astype(int)
        df_copy['Tenure_log'] = np.log1p(df_copy['Tenure'])

        int_cols = ['HasCrCard', 'IsActiveMember', 'NumOfProducts', 'Is_two_products',
                    'Has_Zero_Balance', 'Germany_Female', 'Germany_Inactive']
        cat_cols = ['Geography', 'Age_bin', 'Gender']
        df_copy = FeatureEngineerForAPI.cast_columns(df_copy, int_cols=int_cols, cat_cols=cat_cols)

        cols_to_drop = ['CustomerId', 'Tenure', 'Surname', 'RowNumber']
        df_copy.drop(columns=[col for col in cols_to_drop if col in df_copy.columns], inplace=True, errors='ignore')

        return df_copy

    @staticmethod
    def run_v2_preprocessing(df: pd.DataFrame) -> pd.DataFrame:
        df_copy = FeatureEngineerForAPI.run_v1_preprocessing(df.copy())
        df_copy['is_mature_inactive_transit'] = (
            (df_copy['Has_Zero_Balance'] == 1) & (df_copy['IsActiveMember'] == 0) & (df_copy['Age'] > 40)
        ).astype(int)
        return df_copy

# --- åœ–è¡¨ç”Ÿæˆè¼”åŠ©å‡½å¼ (å±€éƒ¨ SHAP åœ–) ---
def generate_local_shap_chart(shap_data: Dict[str, float], title: str) -> str:
    """
    ä½¿ç”¨ Matplotlib ç¹ªè£½å±€éƒ¨ SHAP å½±éŸ¿åŠ›æ°´å¹³æŸ±ç‹€åœ–ä¸¦è½‰æ›ç‚º Base64 åœ–ç‰‡å­—ä¸²ã€‚
    SHAP å½±éŸ¿åŠ›æ–‡æœ¬å·²æ”¹ç‚ºè‹±æ–‡ã€‚
    """
    if not shap_data:
        logger.warning("SHAP data is empty, unable to draw chart.")
        return ""

    try:
        # æ ¹æ“š SHAP å€¼çš„çµ•å°å€¼é™åºæ’åˆ—ï¼Œå–å‰Nå€‹
        # ç”±æ–¼ SHAP å€¼æ•¸é‡ä¸å¤šï¼Œå–å…¨éƒ¨ä¸¦æ’åº
        sorted_data = dict(sorted(shap_data.items(), key=lambda item: abs(item[1]), reverse=True))
        
        # æº–å‚™ç¹ªåœ–æ•¸æ“š
        features = list(sorted_data.keys())
        importances = list(sorted_data.values())

        # é¡è‰²è¨­ç½®ï¼šæ­£å€¼ï¼ˆæ¨é«˜æµå¤±ï¼‰ç‚ºç´…è‰²ï¼Œè² å€¼ï¼ˆæ¨ä½æµå¤±ï¼‰ç‚ºç¶ è‰²
        colors = ['#EF5350' if imp > 0 else '#66BB6A' for imp in importances]
        
        # ç¹ªåœ–
        plt.style.use('seaborn-v0_8-whitegrid')
        
        fig, ax = plt.subplots(figsize=(10, len(features) * 0.7 + 1))
        
        ax.barh(features, importances, color=colors)
        
        # æ·»åŠ ä¸­å¿ƒç·š (0 è»¸)
        ax.axvline(0, color='grey', linestyle='--', linewidth=0.8)

        # å°‡æ¨™ç±¤æ”¹ç‚ºè‹±æ–‡
        ax.set_xlabel("SHAP Impact (Positive Pushes for Churn / Negative Against)")
        ax.set_title(title, fontsize=14)
        ax.invert_yaxis() # è®“æœ€é‡è¦çš„ç‰¹å¾µåœ¨é ‚éƒ¨

        # è™•ç† Base64 è½‰æ›
        buf = io.BytesIO()
        plt.savefig(buf, format='png', bbox_inches='tight')
        plt.close(fig)
        
        return base64.b64encode(buf.getvalue()).decode('utf-8')

    except Exception as e:
        logger.error(f"Failed to generate local SHAP chart: {e}")
        return ""

# --- Service å¯¦ä¾‹åŒ–èˆ‡å…¨å±€è³‡æºè¼‰å…¥ ---
CHURN_BANK_SERVICE = None
GLOBAL_SHAP_BASE64 = ""

try:
    # 1. åˆå§‹åŒ–æ¨¡å‹æœå‹™
    CHURN_BANK_SERVICE = ChurnBankService(
        model_path=MODEL_PATH_FULL,
        model_dir=MODEL_DIR
    )
    logger.info("ChurnBankService æˆåŠŸåˆå§‹åŒ–ã€‚")

    # 2. è¼‰å…¥é›¢ç·šç”Ÿæˆçš„å…¨å±€ SHAP åœ–è¡¨
    if os.path.exists(GLOBAL_SHAP_FILE):
        with open(GLOBAL_SHAP_FILE, "rb") as f:
            GLOBAL_SHAP_BASE64 = base64.b64encode(f.read()).decode('utf-8')
        logger.info(f"å…¨å±€ SHAP æ‘˜è¦åœ– ({os.path.basename(GLOBAL_SHAP_FILE)}) è¼‰å…¥æˆåŠŸã€‚")
    else:
        logger.warning(f"å…¨å±€ SHAP åœ–è¡¨æª”æ¡ˆæœªæ‰¾åˆ°: {GLOBAL_SHAP_FILE}ã€‚ç„¡æ³•æä¾›å…¨å±€è§£é‡‹åœ–ã€‚")

except Exception as e:
    logger.error(f"åˆå§‹åŒ–æœå‹™æˆ–è¼‰å…¥å…¨å±€è³‡æºå¤±æ•—: {e}")

# --- Blueprint ---
churn_bank_bp = Blueprint('churn_bank_bp', __name__)

@churn_bank_bp.route('/predict', methods=['POST'])
def predict_churn():
    try:
        data = request.get_json()
        if not data:
            raise BadRequest("ç„¡æ•ˆçš„ JSON è«‹æ±‚")

        # 1. æ•´ç†è¼¸å…¥æ•¸æ“š 
        # æ³¨æ„: é€™è£¡ä½¿ç”¨äº†å–®ä¸€é æ¸¬çš„æ•¸å€¼å°æ‡‰ï¼Œèˆ‡ FE å‡½æ•¸ä¸­çš„ replace/map é‚è¼¯ä¸€è‡´
        input_data = {
            # ç¢ºä¿æ‰€æœ‰æ•¸å­—è¼¸å…¥éƒ½æœ‰é è¨­å€¼ï¼Œä¸”ç‚ºæµ®é»æ•¸ï¼Œä»¥è™•ç†æ½›åœ¨çš„ç©ºå€¼æˆ–éæ•¸å­—è¼¸å…¥
            'id': 0, 
            'CreditScore': float(data.get('CreditScore', 650)),
            'Age': float(data.get('Age', 40)),
            'Tenure': float(data.get('Tenure', 5)),
            'Balance': float(data.get('Balance', 0)),
            'NumOfProducts': float(data.get('NumOfProducts', 1)),
            'HasCrCard': float(data.get('HasCrCard', 1)),
            'IsActiveMember': float(data.get('IsActiveMember', 1)),
            'EstimatedSalary': float(data.get('EstimatedSalary', 100000)),
            'Geography': float(data.get('Geography', 0)), 
            'Gender': float(data.get('Gender', 0)), 
            'CustomerId': 0,
            'Surname': 'A',
            'RowNumber': 0
        }

        input_df = pd.DataFrame([input_data])
        
        proba_churn = 0.5
        chart_base64_local = ""
        feature_importance_text = "æ¨¡å‹æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨æ¨¡æ“¬é æ¸¬ï¼Œç„¡æ³•æä¾› AI è§£é‡‹ã€‚"
        final_charts = [] # ç”¨æ–¼æ”¶é›†æ‰€æœ‰åœ–è¡¨çš„åˆ—è¡¨

        if CHURN_BANK_SERVICE and CHURN_BANK_SERVICE.model:
            # 2. å‘¼å« Service å±¤è™•ç†æ•¸æ“šã€é æ¸¬å’Œ SHAP åˆ†æ (å±€éƒ¨)
            prediction_results = CHURN_BANK_SERVICE.preprocess_and_predict(
                input_df=input_df, 
                fe_pipeline_func=FeatureEngineerForAPI.run_v2_preprocessing
            )
            
            # å¾ Service ç²å–çµæœ
            proba_churn = prediction_results['probability']
            feature_importance_text = prediction_results['feature_importance']
            local_shap_values = prediction_results['local_shap_values']
            
            # 3. ç¹ªè£½å±€éƒ¨ SHAP åœ–è¡¨ (ä¿æŒåœ–è¡¨å…§éƒ¨æ¨™é¡Œç‚ºè‹±æ–‡)
            chart_base64_local = generate_local_shap_chart(
                local_shap_values, 
                f"Individual SHAP Local Influence (Churn Probability: {proba_churn:.4f})"
            )
            
            # 4. çµ„è£åœ–è¡¨åˆ—è¡¨ (å±€éƒ¨ SHAP åœ¨å‰ï¼Œå°‡è¿”å›çµ¦å‰ç«¯çš„ title æ”¹å›ä¸­æ–‡)
            if chart_base64_local:
                final_charts.append({
                    "type": "image/png", 
                    "base64_data": chart_base64_local,
                    "title": f"å–®ä¸€å®¢æˆ¶å±€éƒ¨ SHAP å½±éŸ¿åŠ›åˆ†æ ( æµå¤±æ©Ÿç‡ : {proba_churn:.4f} )" # æ”¹å›ä¸­æ–‡æ¨™é¡Œ
                })

        # 5. ç„¡è«–æ˜¯å¦æˆåŠŸé æ¸¬ï¼Œå¦‚æœå…¨å±€åœ–å·²è¼‰å…¥ï¼Œå°±å°‡å…¶åŠ å…¥åˆ—è¡¨ (é€šå¸¸åœ¨ç¬¬äºŒå€‹ä½ç½®ï¼Œå°‡è¿”å›çµ¦å‰ç«¯çš„ title æ”¹å›ä¸­æ–‡)
        if GLOBAL_SHAP_BASE64:
            final_charts.append({
                "type": "image/png", 
                "base64_data": GLOBAL_SHAP_BASE64,
                "title": "æ¨¡å‹å…¨å±€ SHAP æ‘˜è¦åœ– (æ•´é«”ç‰¹å¾µé‡è¦æ€§)" # æ”¹å›ä¸­æ–‡æ¨™é¡Œ
            })
            
        # 6. å¯è®€æ€§è¼¸å‡º (ä¿æŒä¸­æ–‡)
        geography_map = {0: "æ³•åœ‹ (France)", 1: "è¥¿ç­ç‰™ (Spain)", 2: "å¾·åœ‹ (Germany)"}
        gender_map = {0: "ç”·æ€§ (Male)", 1: "å¥³æ€§ (Female)"}
        readable_data = {
            'ä¿¡ç”¨åˆ†æ•¸': data.get('CreditScore', 0),
            'å¹´é½¡': data.get('Age', 0),
            'æœå‹™å¹´é™': data.get('Tenure', 0), # å»ºè­°æ–°å¢é è¨­å€¼
            'é¤˜é¡': f"${float(data.get('Balance',0)):.2f}",
            'ç”¢å“æ•¸é‡': data.get('NumOfProducts', 0), # å»ºè­°æ–°å¢é è¨­å€¼
            'æŒæœ‰ä¿¡ç”¨å¡': "æ˜¯" if data.get('HasCrCard', 0) == 1 else "å¦", # å»ºè­°æ–°å¢é è¨­å€¼
            'æ´»èºæœƒå“¡': "æ˜¯" if data.get('IsActiveMember', 0) == 1 else "å¦", # å»ºè­°æ–°å¢é è¨­å€¼
            'ä¼°è¨ˆè–ªè³‡': f"${float(data.get('EstimatedSalary',0)):.2f}",
            'åœ‹å®¶/åœ°å€': geography_map.get(data.get('Geography', -1), 'æœªçŸ¥'), # ä½¿ç”¨ -1 ä½œç‚ºé è¨­éµ
            'æ€§åˆ¥': gender_map.get(data.get('Gender', -1), 'æœªçŸ¥')            # ä½¿ç”¨ -1 ä½œç‚ºé è¨­éµ
        }
        
        # 7. çµ„è£ç”¨æ–¼ AI è§£é‡‹çš„ Prompt ç‰‡æ®µ (ä¿æŒä¸­æ–‡)
        explanation_prompt_snippet = f"æ¨¡å‹é æ¸¬çš„å®¢æˆ¶æµå¤±æ©Ÿç‡ç‚º {proba_churn:.4f}ã€‚\né—œéµç‰¹å¾µè³‡è¨Š:\n{feature_importance_text}"
        
        return jsonify({
            "status": "success",
            "prediction": float(proba_churn),
            "readable_features": readable_data, 
            "explanation_prompt": explanation_prompt_snippet, 
            "charts": final_charts # è¿”å›åŒ…å«åœ–è¡¨çš„åˆ—è¡¨
        })

    except BadRequest as e:
        logger.error(f"API è«‹æ±‚éŒ¯èª¤: {e}")
        return jsonify({"error": str(e)}), 400
    except ValueError as e:
        logger.error(f"æ•¸æ“šè™•ç†éŒ¯èª¤: {e}")
        return jsonify({"error": f"æ•¸æ“šè™•ç†å¤±æ•—: {e}"}), 400
    except Exception as e:
        logger.error(f"é æ¸¬éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        return jsonify({"error": f"ä¼ºæœå™¨å…§éƒ¨éŒ¯èª¤: {e}"}), 500


@churn_bank_bp.route('/predict_batch', methods=['POST'])
def predict_batch():
    """
    è™•ç† CSV æª”æ¡ˆä¸Šå‚³ï¼Œé€²è¡Œæ‰¹æ¬¡æµå¤±é æ¸¬ï¼Œä¸¦è¿”å›çµæœ JSON æ•¸æ“šã€‚
    """
    logger.info("æ¥æ”¶åˆ°æ‰¹æ¬¡é æ¸¬è«‹æ±‚ã€‚")
    if CHURN_BANK_SERVICE is None or CHURN_BANK_SERVICE.model is None:
        logger.error("æ¨¡å‹æœå‹™æœªå•Ÿå‹•ï¼Œç„¡æ³•é€²è¡Œæ‰¹æ¬¡é æ¸¬ã€‚")
        return jsonify({"error": "æ¨¡å‹æœå‹™æœªå•Ÿå‹•ï¼Œç„¡æ³•é€²è¡Œæ‰¹æ¬¡é æ¸¬ã€‚"}), 503

    # 1. æª¢æŸ¥æª”æ¡ˆæ˜¯å¦ä¸Šå‚³
    if 'file' not in request.files:
        raise BadRequest("è«‹æ±‚ä¸­æœªåŒ…å«æª”æ¡ˆã€‚è«‹ä¸Šå‚³ CSV æª”æ¡ˆã€‚")
    
    file = request.files['file']

    # ä¿®æ­£ Pylance è­¦å‘Šï¼šæª¢æŸ¥ file.filename æ˜¯å¦ç‚º None æˆ–ç©ºå­—ä¸²
    if not file.filename:
        raise BadRequest("æœªé¸æ“‡æª”æ¡ˆæˆ–æª”æ¡ˆåç„¡æ•ˆã€‚")

    # æª¢æŸ¥å‰¯æª”å (ä½¿ç”¨ lower() ç¢ºä¿å¤§å°å¯«ä¸æ•æ„Ÿ)
    if not file.filename.lower().endswith('.csv'):
        raise BadRequest("æª”æ¡ˆæ ¼å¼éŒ¯èª¤ã€‚è«‹ä¸Šå‚³ CSV æª”æ¡ˆã€‚")

    try:
        # 2. è®€å– CSV æª”æ¡ˆè‡³ DataFrame
        # ä½¿ç”¨ io.StringIO è™•ç†æª”æ¡ˆæµï¼Œé¿å…å¯«å…¥ç£ç¢Ÿ
        # è®€å–æ™‚å¼·åˆ¶ä½¿ç”¨ utf-8 è§£ç¢¼
        data_io = io.StringIO(file.read().decode('utf-8'))
        
        # è®€å– CSV æ™‚ï¼Œè®“ Pandas è™•ç†å¯èƒ½å‡ºç¾çš„ç©ºå€¼/NaN
        input_df = pd.read_csv(data_io)
        
        if input_df.empty:
            raise ValueError("CSV æª”æ¡ˆç‚ºç©ºã€‚")

        # æª¢æŸ¥ CSV æ¬„ä½æ˜¯å¦åŒ…å« CustomerId
        if 'CustomerId' not in input_df.columns:
            # é€™æ˜¯æ‰¹æ¬¡é æ¸¬çš„å¿…è¦æ¬„ä½ï¼Œå¦‚æœæ²’æœ‰ï¼Œå°±æ‹‹å‡ºéŒ¯èª¤
            raise ValueError("CSV æª”æ¡ˆä¸­ç¼ºå°‘å¿…è¦çš„ 'CustomerId' æ¬„ä½ã€‚")

        # 3. å‘¼å« Service å±¤é€²è¡Œæ‰¹æ¬¡é æ¸¬
        # Service å±¤æœƒè™•ç†ç‰¹å¾µå·¥ç¨‹å’Œå°é½Šï¼Œè¿”å›åŒ…å« 'CustomerId' å’Œ 'Exited_Probability' çš„ DataFrame
        result_df = CHURN_BANK_SERVICE.predict_batch_csv(
            input_df=input_df, 
            fe_pipeline_func=FeatureEngineerForAPI.run_v2_preprocessing
        )
        
        # 4. æº–å‚™ JSON å›æ‡‰ï¼šåªä¿ç•™éœ€è¦çš„æ¬„ä½ï¼Œä¸¦è™•ç† NaN
        
        # åƒ…ä¿ç•™ CustomerId å’Œ Exited_Probability æ¬„ä½
        result_df_cleaned = result_df[['CustomerId', 'Exited_Probability']].copy()
        
        # â˜…â˜…â˜… é—œéµä¿®æ­£ï¼šè™•ç† NaN å€¼ï¼Œæ›¿æ›ç‚º 0.0 ä»¥é¿å…ç”¢ç”Ÿéæ³•çš„ JSON å…ƒç´  'NaN' â˜…â˜…â˜…
        # é€™ç¢ºä¿äº†æ‰€æœ‰æ•¸å€¼åœ¨è½‰æ›ç‚º JSON å‰éƒ½æ˜¯åˆæ³•çš„ float/int
        result_df_cleaned['CustomerId'] = result_df_cleaned['CustomerId'].fillna(0.0)
        result_df_cleaned['Exited_Probability'] = result_df_cleaned['Exited_Probability'].fillna(0.0)
        
        # å°‡æ¬„ä½åç¨±è½‰æ›ç‚ºå‰ç«¯æœŸæœ›çš„éµå (camelCase)
        result_list = result_df_cleaned.rename(columns={
            'CustomerId': 'customerId', 
            'Exited_Probability': 'probability'
        }).to_dict('records')
        
        # 5. ä½œç‚º JSON å›æ‡‰çµ¦å‰ç«¯
        return jsonify({
            "status": "success",
            "message": f"æˆåŠŸé æ¸¬ {len(result_list)} ç­†è³‡æ–™ã€‚",
            "data": result_list # è¿”å›é æ¸¬çµæœåˆ—è¡¨
        })

    except BadRequest as e:
        logger.error(f"æ‰¹æ¬¡ API è«‹æ±‚éŒ¯èª¤: {e}")
        return jsonify({"error": str(e)}), 400
    except ValueError as e:
        logger.error(f"æ‰¹æ¬¡æ•¸æ“šè™•ç†éŒ¯èª¤ (CSV å…§å®¹): {e}")
        return jsonify({"error": f"CSV å…§å®¹æ ¼å¼éŒ¯èª¤: {e}"}), 400
    except RuntimeError as e:
        logger.error(f"æ¨¡å‹é æ¸¬å¤±æ•—: {e}")
        return jsonify({"error": str(e)}), 503
    except Exception as e:
        logger.error(f"æ‰¹æ¬¡é æ¸¬éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        return jsonify({"error": f"ä¼ºæœå™¨å…§éƒ¨éŒ¯èª¤: {e}"}), 500