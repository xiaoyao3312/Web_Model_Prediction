# services/churn_bank_service.py

import joblib
import numpy as np
import os
import pandas as pd
from typing import Dict, Any, List, Callable
import shap
import logging
# ğŸš¨ ç‚ºäº†è®“æœå‹™èƒ½ç¨ç«‹é‹è¡Œï¼Œæˆ‘å€‘ä¸ç›´æ¥å¾ train.py å°å…¥ FeatureEngineerï¼Œè€Œæ˜¯å‡è¨­
# å¤–éƒ¨æœƒæä¾› FE å‡½æ•¸ï¼ˆä¾‹å¦‚ routes.py ä¸­çš„ FeatureEngineerForAPIï¼‰

logger = logging.getLogger('ChurnBankService')
logger.setLevel(logging.INFO)

class ChurnBankService:
    def __init__(self, model_path: str, model_dir: str):
        self.model = self._load_model(model_path)
        self.model_dir = model_dir
        
        # è¼‰å…¥è¨“ç·´æ™‚ä¿å­˜çš„ç‰¹å¾µåˆ—è¡¨å’Œ FE ç®¡é“åç¨±
        self.feature_cols, self.fe_pipeline_name = self._load_model_artifacts(model_dir)
        
        # å»ºç«‹ SHAP Explainer (åœ¨æœå‹™å•Ÿå‹•æ™‚ä¸€æ¬¡æ€§å®Œæˆ)
        # åƒ…ç•¶æ¨¡å‹æˆåŠŸè¼‰å…¥æ™‚æ‰åˆå§‹åŒ– Explainer
        if self.model:
            try:
                self.explainer = shap.TreeExplainer(self.model)
                logger.info("SHAP TreeExplainer æˆåŠŸåˆå§‹åŒ–ã€‚")
            except Exception as e:
                logger.warning(f"åˆå§‹åŒ– SHAP TreeExplainer å¤±æ•—: {e}")
                self.explainer = None
        else:
            self.explainer = None

    def _load_model_artifacts(self, model_dir: str) -> tuple[List[str], str]:
        """è¼‰å…¥è¨“ç·´è…³æœ¬ç”¢ç”Ÿçš„ç‰¹å¾µåˆ—è¡¨å’Œ FE ç®¡é“åç¨±ã€‚"""
        feature_cols_path = os.path.join(model_dir, 'feature_columns.joblib')
        fe_name_path = os.path.join(model_dir, 'fe_pipeline_name.txt')
        
        if not os.path.exists(feature_cols_path) or not os.path.exists(fe_name_path):
             logger.warning(f"æ¨¡å‹å·¥ä»¶ (feature_columns/fe_pipeline_name) æœªæ‰¾åˆ°æ–¼ {model_dir}")
             return [], "" # è¿”å›ç©ºåˆ—è¡¨å’Œç©ºå­—ç¬¦ä¸²ï¼Œä»¥ä¾¿å¾ŒçºŒä½¿ç”¨æ¨¡æ“¬é æ¸¬

        try:
            feature_cols = joblib.load(feature_cols_path)
            with open(fe_name_path, 'r') as f:
                fe_pipeline_name = f.read().strip()
            logger.info(f"ç‰¹å¾µåˆ— ({len(feature_cols)}) å’Œ FE ç®¡é“åç¨± ({fe_pipeline_name}) è¼‰å…¥æˆåŠŸã€‚")
            return feature_cols, fe_pipeline_name
        except Exception as e:
            logger.error(f"è¼‰å…¥æ¨¡å‹å·¥ä»¶å¤±æ•—: {e}")
            return [], ""

    def _load_model(self, model_path: str) -> Any:
        """è¼‰å…¥é è¨“ç·´çš„æ©Ÿå™¨å­¸ç¿’æ¨¡å‹ã€‚"""
        if not os.path.exists(model_path):
            logger.warning(f"æ¨¡å‹æª”æ¡ˆæœªæ‰¾åˆ°: {model_path}")
            return None
        try:
            model = joblib.load(model_path)
            logger.info(f"æ¨¡å‹ {model_path} è¼‰å…¥æˆåŠŸã€‚")
            return model
        except Exception as e:
            logger.error(f"è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
            return None

    def _align_features(self, df_processed: pd.DataFrame) -> pd.DataFrame:
        """æ ¹æ“šè¨“ç·´æ™‚çš„ç‰¹å¾µåˆ—è¡¨é€²è¡Œ OHE å’Œæ¬„ä½å°é½Šã€‚"""
        if not self.feature_cols:
            raise RuntimeError("ç‰¹å¾µæ¬„ä½åˆ—è¡¨æœªè¼‰å…¥ã€‚")

        # æ‰¾å‡ºé¡åˆ¥æ¬„ä½ (Geography, Age_bin ç­‰)
        # 'category' é¡å‹æ˜¯ pandas æ¨è–¦çš„ FE è¼¸å‡ºé¡å‹
        cat_cols = [col for col in df_processed.columns if df_processed[col].dtype.name in ['object', 'str', 'category']]
        
        # å°æ•¸æ“šé€²è¡Œ One-Hot Encoding
        X_oh = pd.get_dummies(df_processed, columns=cat_cols, dummy_na=False)
        
        # è£œé½Šè¨“ç·´é›†ç¼ºå°‘çš„æ¬„ä½ (ç•¶å‰å–®ä¸€è«‹æ±‚å¯èƒ½ç¼ºå°‘æŸå€‹ OHE æ¬„ä½)
        missing_cols = set(self.feature_cols) - set(X_oh.columns)
        for c in missing_cols:
             X_oh[c] = 0.0
        
        # ç§»é™¤å¤šé¤˜çš„æ¬„ä½ï¼Œä¸¦ç¢ºä¿é †åºä¸€è‡´
        # é€™ä¸€æ­¥æ˜¯é—œéµï¼šç¢ºä¿é æ¸¬æ•¸æ“šçš„æ¬„ä½åç¨±å’Œé †åºèˆ‡è¨“ç·´æ¨¡å‹æ™‚å®Œå…¨ç›¸åŒ
        X_predict = X_oh[[col for col in self.feature_cols if col in X_oh.columns]]
        X_predict = X_predict.astype(float)

        if X_predict.shape[1] != len(self.feature_cols):
             raise ValueError(f"ç‰¹å¾µæ•¸é‡ä¸åŒ¹é…ã€‚é æœŸ {len(self.feature_cols)}ï¼Œå¯¦éš› {X_predict.shape[1]}")
        
        return X_predict

    def get_local_shap(self, X_predict: pd.DataFrame) -> Dict[str, float]:
        """è¨ˆç®—å–®ä¸€æ¨£æœ¬çš„å±€éƒ¨ SHAP å€¼ï¼Œä¸¦è½‰æ›ç‚ºå¯è®€çš„å­—å…¸ã€‚"""
        if not self.explainer:
             return {} # Explainer æœªåˆå§‹åŒ–å‰‡è¿”å›ç©º

        try:
            # è¨ˆç®— SHAP å€¼
            # shap_values å¯èƒ½æ˜¯ (1, num_features) çš„ numpy array
            shap_values = self.explainer.shap_values(X_predict, check_additivity=False)
            
            # ç”±æ–¼ XGBoost æ˜¯äºŒåˆ†é¡ï¼Œshap_values æ˜¯å…©å€‹é™£åˆ—çš„åˆ—è¡¨ (list of arrays)ï¼Œå–é¡åˆ¥ 1 çš„å€¼
            # ç¢ºä¿ shap_values_row æ˜¯ä¸€å€‹ä¸€ç¶­é™£åˆ—
            shap_values_row = shap_values[1][0] if isinstance(shap_values, list) else shap_values[0] 
            
            feature_names = X_predict.columns
            shap_dict = dict(zip(feature_names, shap_values_row))
            
            # æ’åº (ä»¥ SHAP å€¼çš„çµ•å°å€¼é™åºæ’åˆ—)
            sorted_shap = dict(sorted(shap_dict.items(), key=lambda item: abs(item[1]), reverse=True))
            
            # ç‚ºäº†ç°¡åŒ– API è¼¸å‡ºï¼Œæˆ‘å€‘åªè¿”å›å‰ 7 å€‹æœ€æœ‰å½±éŸ¿åŠ›çš„ç‰¹å¾µ
            top_n_shap = {k: float(v) for k, v in list(sorted_shap.items())[:7]}
            
            return top_n_shap
        except Exception as e:
            logger.error(f"è¨ˆç®—å±€éƒ¨ SHAP å€¼å¤±æ•—: {e}")
            return {}


    def preprocess_and_predict(self, input_df: pd.DataFrame, fe_pipeline_func: Callable) -> Dict[str, Any]:
        """
        è™•ç†è¼¸å…¥æ•¸æ“šï¼Œé€²è¡Œç‰¹å¾µå·¥ç¨‹ï¼Œç„¶å¾Œé€²è¡Œé æ¸¬ã€‚
        
        Args:
            input_df: å·²ç¶“åŒ…å«åŸå§‹ç‰¹å¾µçš„ DataFrame (å–®è¡Œ)ã€‚
            fe_pipeline_func: å¾ routes å±¤å‚³éä¸‹ä¾†çš„ FE å‡½æ•¸ (e.g., run_v2_preprocessing)ã€‚
            
        Returns:
            åŒ…å«é æ¸¬çµæœã€æ©Ÿç‡å’Œå±€éƒ¨ SHAP æ•¸æ“šçš„å­—å…¸ã€‚
        """
        
        if self.model is None:
            # è¿”å›æ¨¡æ“¬çµæœ
            return {
                "prediction": 0,
                "probability": 0.5,
                "feature_importance": "æ¨¡å‹æœå‹™æœªå•Ÿå‹•ï¼Œä½¿ç”¨æ¨¡æ“¬é æ¸¬ã€‚",
                "local_shap_values": {}
            }
        
        # 1. ç‰¹å¾µå·¥ç¨‹ (ä½¿ç”¨ routes å±¤æä¾›çš„ FE å‡½æ•¸)
        processed_df = fe_pipeline_func(input_df.copy())
        
        # 2. OHE å’Œç‰¹å¾µå°é½Š
        X_predict = self._align_features(processed_df)

        # 3. é€²è¡Œé æ¸¬
        probability_class_1 = self.model.predict_proba(X_predict)[:, 1][0]
        prediction = int(probability_class_1 >= 0.5)

        # 4. é€²è¡Œå±€éƒ¨ SHAP åˆ†æ
        local_shap_values = self.get_local_shap(X_predict)
        
        # 5. è½‰æ›ç‚ºå¯è®€çš„ç‰¹å¾µé‡è¦æ€§æ–‡æœ¬ (ç”¨æ–¼ AI è§£é‡‹)
        feature_importance_text = "ä¸»è¦å½±éŸ¿å› ç´  (å±€éƒ¨ SHAP å€¼):\n"
        if local_shap_values:
            for feature, shap_value in local_shap_values.items():
                # SHAP å€¼ > 0 è¡¨ç¤ºæ¨é«˜æµå¤±æ©Ÿç‡
                sign = "æ¨é«˜æµå¤±æ©Ÿç‡ (+)" if shap_value > 0 else "æ¨ä½æµå¤±æ©Ÿç‡ (-)"
                feature_importance_text += f"- {feature}: {sign} (å½±éŸ¿å€¼: {abs(shap_value):.4f})\n"
        else:
             feature_importance_text = "SHAP åˆ†æå·¥å…·æœªæˆåŠŸåˆå§‹åŒ–æˆ–è¨ˆç®—å¤±æ•—ã€‚"

        return {
            "prediction": prediction,
            "probability": float(probability_class_1),
            "feature_importance": feature_importance_text,
            "local_shap_values": local_shap_values
        }